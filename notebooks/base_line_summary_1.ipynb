{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import networkx as nx\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_neg = pd.read_json('/Users/williamfussell/Downloads/df_neg_sample.json')\n",
    "df_pos = pd.read_json('/Users/williamfussell/Downloads/df_pos_sample.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004X145</td>\n",
       "      <td>Why would anyone make an oil drain pan with a ...</td>\n",
       "      <td>Difficult to pour oil out of this pan</td>\n",
       "      <td>1390003200</td>\n",
       "      <td>0</td>\n",
       "      <td>Flotool International 05070 7-1/2 Quart Round ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004X145</td>\n",
       "      <td>Why would anyone make an oil drain pan with a ...</td>\n",
       "      <td>Difficult to pour oil out of this pan</td>\n",
       "      <td>1390003200</td>\n",
       "      <td>0</td>\n",
       "      <td>Flotool International 05070 7-1/2 Quart Round ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004X145</td>\n",
       "      <td>this item is flimsy when filled with 5 quarts ...</td>\n",
       "      <td>dont buy this</td>\n",
       "      <td>1382227200</td>\n",
       "      <td>0</td>\n",
       "      <td>Flotool International 05070 7-1/2 Quart Round ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>B00004X145</td>\n",
       "      <td>this item is flimsy when filled with 5 quarts ...</td>\n",
       "      <td>dont buy this</td>\n",
       "      <td>1382227200</td>\n",
       "      <td>0</td>\n",
       "      <td>Flotool International 05070 7-1/2 Quart Round ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>B00004X145</td>\n",
       "      <td>I bought this because it was inexpensive and I...</td>\n",
       "      <td>Not my favorite</td>\n",
       "      <td>1355875200</td>\n",
       "      <td>0</td>\n",
       "      <td>Flotool International 05070 7-1/2 Quart Round ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall        asin                                         reviewText  \\\n",
       "0        1  B00004X145  Why would anyone make an oil drain pan with a ...   \n",
       "1        1  B00004X145  Why would anyone make an oil drain pan with a ...   \n",
       "2        1  B00004X145  this item is flimsy when filled with 5 quarts ...   \n",
       "3        1  B00004X145  this item is flimsy when filled with 5 quarts ...   \n",
       "4        2  B00004X145  I bought this because it was inexpensive and I...   \n",
       "\n",
       "                                 summary  unixReviewTime  sentiment  \\\n",
       "0  Difficult to pour oil out of this pan      1390003200          0   \n",
       "1  Difficult to pour oil out of this pan      1390003200          0   \n",
       "2                          dont buy this      1382227200          0   \n",
       "3                          dont buy this      1382227200          0   \n",
       "4                        Not my favorite      1355875200          0   \n",
       "\n",
       "                                               title  \n",
       "0  Flotool International 05070 7-1/2 Quart Round ...  \n",
       "1  Flotool International 05070 7-1/2 Quart Round ...  \n",
       "2  Flotool International 05070 7-1/2 Quart Round ...  \n",
       "3  Flotool International 05070 7-1/2 Quart Round ...  \n",
       "4  Flotool International 05070 7-1/2 Quart Round ...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the data\n",
    "df_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26284 entries, 1162 to 1709446\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   overall         26284 non-null  int64 \n",
      " 1   asin            26284 non-null  object\n",
      " 2   reviewText      26284 non-null  object\n",
      " 3   summary         26284 non-null  object\n",
      " 4   unixReviewTime  26284 non-null  int64 \n",
      " 5   sentiment       26284 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_neu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>B0000AXCCQ</td>\n",
       "      <td>Lots of storage. Not so easy to mount. All tra...</td>\n",
       "      <td>Does the job.</td>\n",
       "      <td>1401408000</td>\n",
       "      <td>2</td>\n",
       "      <td>Buyers Products 1701680 Black Poly Trailer Ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>B0000AXCCQ</td>\n",
       "      <td>Lots of storage. Not so easy to mount. All tra...</td>\n",
       "      <td>Does the job.</td>\n",
       "      <td>1401408000</td>\n",
       "      <td>2</td>\n",
       "      <td>Buyers Products 1701680 Black Poly Trailer Ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>B0000AXCCQ</td>\n",
       "      <td>I'm very happy with this purchase. Some of the...</td>\n",
       "      <td>Great box for the price!</td>\n",
       "      <td>1393459200</td>\n",
       "      <td>2</td>\n",
       "      <td>Buyers Products 1701680 Black Poly Trailer Ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>B0000AXCCQ</td>\n",
       "      <td>I'm very happy with this purchase. Some of the...</td>\n",
       "      <td>Great box for the price!</td>\n",
       "      <td>1393459200</td>\n",
       "      <td>2</td>\n",
       "      <td>Buyers Products 1701680 Black Poly Trailer Ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B0000AXCCQ</td>\n",
       "      <td>This is a very good box for the money and it i...</td>\n",
       "      <td>Nice Box.</td>\n",
       "      <td>1498953600</td>\n",
       "      <td>2</td>\n",
       "      <td>Buyers Products 1701680 Black Poly Trailer Ton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall        asin                                         reviewText  \\\n",
       "0        4  B0000AXCCQ  Lots of storage. Not so easy to mount. All tra...   \n",
       "1        4  B0000AXCCQ  Lots of storage. Not so easy to mount. All tra...   \n",
       "2        5  B0000AXCCQ  I'm very happy with this purchase. Some of the...   \n",
       "3        5  B0000AXCCQ  I'm very happy with this purchase. Some of the...   \n",
       "4        5  B0000AXCCQ  This is a very good box for the money and it i...   \n",
       "\n",
       "                    summary  unixReviewTime  sentiment  \\\n",
       "0             Does the job.      1401408000          2   \n",
       "1             Does the job.      1401408000          2   \n",
       "2  Great box for the price!      1393459200          2   \n",
       "3  Great box for the price!      1393459200          2   \n",
       "4                 Nice Box.      1498953600          2   \n",
       "\n",
       "                                               title  \n",
       "0  Buyers Products 1701680 Black Poly Trailer Ton...  \n",
       "1  Buyers Products 1701680 Black Poly Trailer Ton...  \n",
       "2  Buyers Products 1701680 Black Poly Trailer Ton...  \n",
       "3  Buyers Products 1701680 Black Poly Trailer Ton...  \n",
       "4  Buyers Products 1701680 Black Poly Trailer Ton...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I bought this because it was inexpensive and I thought 6 quarts was large enough\"\n",
      "\n",
      "\"Unfortunately I did not think far enough ahead\"\n",
      "\n",
      "\"My truck has 5qt oil capacity, and this container will hold a maximum of 6qts on a flat surface\"\n",
      "\n",
      "\"I bought this because it was inexpensive and I thought 6 quarts was large enough\"\n",
      "\n",
      "\"Unfortunately I did not think far enough ahead\"\n",
      "\n",
      "\"My truck has 5qt oil capacity, and this container will hold a maximum of 6qts on a flat surface\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for a specific 'asin' value (product)\n",
    "product_asin = df_neg['asin'][2]\n",
    "product_reviews = df_neg[df_neg['asin'] == product_asin]['reviewText'].tolist()\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to calculate BERT embeddings for a sentence\n",
    "def get_bert_embedding(sentence):\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    inputs = torch.tensor([input_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate BERT embeddings for all sentences\n",
    "sentence_embeddings = [get_bert_embedding(sentence) for sentence in product_reviews]\n",
    "\n",
    "# Calculate cosine similarity between sentences\n",
    "cosine_similarities = cosine_similarity(np.vstack(sentence_embeddings))\n",
    "\n",
    "# Get the average cosine similarity score for each review\n",
    "average_cosine_similarities = cosine_similarities.mean(axis=1)\n",
    "\n",
    "# Select the indices of the top three reviews based on their average cosine similarity score\n",
    "top_review_indices = np.argsort(average_cosine_similarities)[-num_sentences_in_summary:]\n",
    "\n",
    "# Generate the extractive summary by selecting sentences from the top reviews\n",
    "extractive_summary = []\n",
    "for i in top_review_indices:\n",
    "    sentences = product_reviews[i].split('. ')  # Split the review into sentences\n",
    "    selected_sentences = sentences[:min(3, len(sentences))]  # Select up to 3 sentences\n",
    "    extractive_summary.extend(selected_sentences)\n",
    "\n",
    "# Create a string with extracted sentences enclosed in double quotes and separated by newline characters\n",
    "formatted_summary = '\\n'.join(['\"' + sentence + '\"\\n' for sentence in extractive_summary])\n",
    "\n",
    "# Print the formatted extractive summary\n",
    "print(formatted_summary)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-2 F1 Score: 0.0\n",
      "ROUGE-L F1 Score: 0.19565216919896042\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# Instantiate the ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Define your extractive summary and reference summary as strings\n",
    "extractive_summary = (\n",
    "\"I bought this because it was inexpensive and I thought 6 quarts was large enough\"\n",
    "\n",
    "\"Unfortunately I did not think far enough ahead\"\n",
    "\n",
    "\"My truck has 5qt oil capacity, and this container will hold a maximum of 6qts on a flat surface\"\n",
    "\n",
    "\"I bought this because it was inexpensive and I thought 6 quarts was large enough\"\n",
    "\n",
    "\"Unfortunately I did not think far enough ahead\"\n",
    "\n",
    "\"My truck has 5qt oil capacity, and this container will hold a maximum of 6qts on a flat surface\"\n",
    ")\n",
    "\n",
    "reference_summary = (\n",
    "    \"The reviews express the buyer's initial satisfaction with the cost and perceived adequacy of a 6-quart container. However, they later realized its limitations, as their truck requires 5 quarts of oil and the container's maximum capacity is only slightly higher at 6 quarts, which might be insufficient for their needs. This realization comes from not having fully anticipated their requirements when making the purchase.\"\n",
    ")\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(extractive_summary, reference_summary)\n",
    "\n",
    "# Access specific ROUGE metrics (e.g., ROUGE-2, ROUGE-L)\n",
    "rouge_2_f1 = scores[0][\"rouge-2\"][\"f\"]\n",
    "rouge_l_f1 = scores[0][\"rouge-l\"][\"f\"]\n",
    "\n",
    "# Print the scores\n",
    "print(\"ROUGE-2 F1 Score:\", rouge_2_f1)\n",
    "print(\"ROUGE-L F1 Score:\", rouge_l_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why would anyone make an oil drain pan with a spout that is flush with the top rim?\n",
      "That's not a spout.\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Filter the DataFrame for a specific 'asin' value (product)\n",
    "product_asin = df_neg['asin'][2]\n",
    "product_reviews = df_neg[df_neg['asin'] == product_asin]['reviewText'].tolist()\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to calculate BERT embeddings for a sentence\n",
    "def get_bert_embedding(sentence):\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    inputs = torch.tensor([input_ids])\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Calculate BERT embeddings for all sentences\n",
    "sentence_embeddings = [get_bert_embedding(sentence) for sentence in product_reviews]\n",
    "\n",
    "# Flatten the 3D embeddings into 2D arrays\n",
    "sentence_embeddings = [embedding.squeeze() for embedding in sentence_embeddings]\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Calculate cosine similarity between BERT embeddings and add edges to the graph\n",
    "num_sentences = len(product_reviews)\n",
    "cosine_similarities = cosine_similarity(sentence_embeddings, sentence_embeddings)\n",
    "\n",
    "# Tokenize sentences and preprocess\n",
    "sentences = sent_tokenize(\" \".join(product_reviews))\n",
    "\n",
    "# Add nodes (sentences) to the graph\n",
    "for i, sentence in enumerate(sentences):\n",
    "    G.add_node(i, text=sentence)\n",
    "\n",
    "# Add edges to the graph based on cosine similarities\n",
    "for i in range(num_sentences):\n",
    "    for j in range(i + 1, num_sentences):\n",
    "        similarity = cosine_similarities[i][j]\n",
    "        G.add_edge(i, j, weight=similarity)\n",
    "\n",
    "# Calculate TextRank scores\n",
    "scores = nx.pagerank(G)\n",
    "\n",
    "# Select the top sentences based on TextRank scores\n",
    "num_sentences_in_summary = 2  # Adjust as needed\n",
    "summary_indices = sorted(range(len(sentences)), key=lambda i: scores[i], reverse=True)[:num_sentences_in_summary]\n",
    "summary = [sentences[i] for i in summary_indices]\n",
    "\n",
    "# Print the extractive summary\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-2 F1 Score: 0.0\n",
      "ROUGE-L F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "# Instantiate the ROUGE scorer\n",
    "rouge = Rouge()\n",
    "\n",
    "# Define your extractive summary and reference summary as strings\n",
    "extractive_summary = (\n",
    "    \"Quality control is suspected.\"\n",
    "    \"Its just not as expected.\"\n",
    ")\n",
    "\n",
    "reference_summary = (\n",
    "    \"Customers express disappointment with this car vacuum, citing its poor performance and tendency to blow fuses. They find it lacks the suction power needed for effective cleaning, and some report issues with build quality, including a damaged cord and attachment problems. Despite its initial promise, this vacuum falls short of expectations, leaving buyers frustrated and dissatisfied.\"\n",
    ")\n",
    "\n",
    "# Calculate ROUGE scores\n",
    "scores = rouge.get_scores(extractive_summary, reference_summary)\n",
    "\n",
    "# Access specific ROUGE metrics (e.g., ROUGE-2, ROUGE-L)\n",
    "rouge_2_f1 = scores[0][\"rouge-2\"][\"f\"]\n",
    "rouge_l_f1 = scores[0][\"rouge-l\"][\"f\"]\n",
    "\n",
    "# Print the scores\n",
    "print(\"ROUGE-2 F1 Score:\", rouge_2_f1)\n",
    "print(\"ROUGE-L F1 Score:\", rouge_l_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
